{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import textwrap\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from scipy.spatial.transform import Rotation\n",
    "from scipy.spatial.distance import pdist, cdist, squareform\n",
    "\n",
    "from PIL import Image\n",
    "from PIL.Image import Image as PilImage\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "\n",
    "def add_path(path):\n",
    "    if path not in sys.path:\n",
    "        sys.path.insert(0, path)\n",
    "\n",
    "THIS_DIR = os.path.dirname('./')\n",
    "LIB_PATH = os.path.join(THIS_DIR, '..')\n",
    "add_path(LIB_PATH)\n",
    "\n",
    "import utils.misc as ws\n",
    "import utils.data_utils\n",
    "import utils.train_utils\n",
    "import utils.eval_utils\n",
    "import utils.mesh\n",
    "import utils.dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actual_idx(training_contact_maps, global_idx):\n",
    "    _path_split = training_contact_maps[global_idx].split(\"/\")\n",
    "    return (_path_split[-2], _path_split[-1].split(\".\")[0].split(\"_\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = os.path.join(LIB_PATH, '../dataset_train/')\n",
    "validation_dir = os.path.join(LIB_PATH, '../dataset_validation/')\n",
    "\n",
    "# object_model = \"003_cracker_box_google_16k_textured_scale_1000\"\n",
    "object_model = \"005_tomato_soup_can_google_16k_textured_scale_1000\"\n",
    "\n",
    "EXPERIMENTS_DIR = '../experiments/all5_005_dsdf_50_varcmap'\n",
    "\n",
    "images_dir = os.path.join(dataset_dir, object_model, \"images\")\n",
    "contactmap_dir = os.path.join(dataset_dir, object_model, \"contactmap\")\n",
    "\n",
    "CHECKPOINT = 'latest'\n",
    "split_file = os.path.join(EXPERIMENTS_DIR, 'split_train.json')\n",
    "specs_filename = os.path.join(EXPERIMENTS_DIR, \"specs.json\")\n",
    "\n",
    "with open(split_file, 'r') as f:\n",
    "    data_split = json.load(f)\n",
    "\n",
    "\n",
    "LATENT_CODE_DIR = ws.latent_codes_subdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gripper idxs: {'Allegro': 0, 'Barrett': 1, 'HumanHand': 2, 'fetch_gripper': 3, 'panda_grasp': 4}\n"
     ]
    }
   ],
   "source": [
    "# This has all the necessary information\n",
    "sdf_dataset = utils.dataset.MultiGripperSamples(dataset_dir, data_split, subsample=16000)\n",
    "trn_cmap_dist = sdf_dataset.cmap_dist\n",
    "trn_cmap_sim = 1 - trn_cmap_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 torch.Size([250, 128])\n",
      "(250, 250)\n"
     ]
    }
   ],
   "source": [
    "# Load the latent vectors and construct a N,N distance matrix between them\n",
    "\n",
    "specs = json.load(open(specs_filename))\n",
    "latent_size = specs[\"CodeLength\"]\n",
    "latent_vecs = ws.load_latent_vectors(EXPERIMENTS_DIR, CHECKPOINT)\n",
    "print(latent_size, latent_vecs.shape)\n",
    "\n",
    "lv_numpy = latent_vecs.cpu().numpy()\n",
    "\n",
    "lv_dist = squareform(pdist(lv_numpy, metric='cityblock'))\n",
    "lv_dist /= np.max(lv_dist)\n",
    "print(lv_dist.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_matches(cmap_dist, lv_dist, N, extreme_end=5):\n",
    "    count_near = 0\n",
    "    count_far = 0\n",
    "\n",
    "    setdiff_near = 0.0\n",
    "    setdiff_far = 0.0\n",
    "\n",
    "    count_top1 = 0\n",
    "    count_topK = 0\n",
    "\n",
    "    for q in range(N):\n",
    "        topK_query_cmap = np.argsort(cmap_dist[q])\n",
    "        topK_query_lv = np.argsort(lv_dist[q])\n",
    "        \n",
    "        # if set(topK_query_cmap[1:extreme_end+1]) == set(topK_query_lv[1:extreme_end+1]):\n",
    "        #     count_near += 1\n",
    "        # if set(topK_query_cmap[-extreme_end:]) == set(topK_query_lv[-extreme_end:]):\n",
    "        #     count_far += 1\n",
    "        \n",
    "        # Count the different elements\n",
    "        setdiff_near += len(set(topK_query_cmap[1:extreme_end+1]) ^ set(topK_query_lv[1:extreme_end+1]))\n",
    "        setdiff_far += len(set(topK_query_cmap[-extreme_end:]) ^ set(topK_query_lv[-extreme_end:]))\n",
    "        \n",
    "        # top-1\n",
    "        if topK_query_cmap[1] == topK_query_lv[1]:\n",
    "            count_top1 += 1\n",
    "        \n",
    "        # top-5 -- [:6] since first element is the same as query!\n",
    "        if topK_query_cmap[1] in topK_query_lv[1:extreme_end+1]:\n",
    "            count_topK += 1\n",
    "\n",
    "    setdiff_near /= N\n",
    "    setdiff_far /= N\n",
    "    \n",
    "    # return count_near, count_far, setdiff_near, setdiff_far, count_top1/N, count_top5/N\n",
    "    return setdiff_near, setdiff_far, count_top1/N, count_topK/N\n",
    "\n",
    "\n",
    "def check_avg_sim(cmap_dist, lv_dist, cmap_sim, K=1):\n",
    "    sim_topK = 0\n",
    "    sim_cmap = 0\n",
    "    far_topK = 0\n",
    "    far_cmap = 0\n",
    "    N = len(cmap_dist) # number of validation samples\n",
    "    for q in range(N):\n",
    "        topK_query_cmap = np.argsort(cmap_dist[q])\n",
    "        topK_query_lv = np.argsort(lv_dist[q])\n",
    "        # Nearest\n",
    "        sim_topK += np.mean(cmap_sim[q][topK_query_lv[1:K+1]])\n",
    "        sim_cmap += np.mean(cmap_sim[q][topK_query_cmap[1:K+1]])\n",
    "        # Farthest\n",
    "        far_topK += np.mean(cmap_sim[q][topK_query_lv[-K:]])\n",
    "        far_cmap += np.mean(cmap_sim[q][topK_query_cmap[-K:]])\n",
    "    return sim_topK/N, sim_cmap/N, far_topK/N, far_cmap/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.304, 1.696, 0.64, 0.832)\n",
      "(1.88, 2.208, 0.64, 0.904)\n",
      "(2.792, 3.232, 0.64, 0.932)\n",
      "(4.176, 4.672, 0.64, 0.968)\n"
     ]
    }
   ],
   "source": [
    "print(check_matches(sdf_dataset.cmap_dist, lv_dist, len(sdf_dataset), extreme_end=2))\n",
    "\n",
    "print(check_matches(sdf_dataset.cmap_dist, lv_dist, len(sdf_dataset), extreme_end=3))\n",
    "\n",
    "print(check_matches(sdf_dataset.cmap_dist, lv_dist, len(sdf_dataset), extreme_end=5))\n",
    "\n",
    "print(check_matches(sdf_dataset.cmap_dist, lv_dist, len(sdf_dataset), extreme_end=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=1 (0.7829037137586227, 0.791538979273289, 0.12050250911444393, 0.09844150558390569)\n",
      "K=3 (0.7529259250979239, 0.7617268475424762, 0.14014646755108362, 0.12377894410689155)\n",
      "K=5 (0.7361010385875519, 0.7439354169143236, 0.15567472821006892, 0.1418084257351176)\n"
     ]
    }
   ],
   "source": [
    "print(\"K=1\", check_avg_sim(trn_cmap_dist, lv_dist, trn_cmap_sim, 1))\n",
    "print(\"K=3\", check_avg_sim(trn_cmap_dist, lv_dist, trn_cmap_sim, 3))\n",
    "print(\"K=5\", check_avg_sim(trn_cmap_dist, lv_dist, trn_cmap_sim, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_idx = 188\n",
    "\n",
    "query_gripper, query_gnum = get_actual_idx(sdf_dataset.cmaps, query_idx)\n",
    "\n",
    "topK_query_cmap = np.argsort(sdf_dataset.cmap_dist[query_idx])\n",
    "\n",
    "topK_query_lv = np.argsort(lv_dist[query_idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 15\n",
    "print(\"Nearest\")\n",
    "print(\"GT Cmap:\", topK_query_cmap[:K])\n",
    "print(\"Pred LV:\", topK_query_lv[:K])\n",
    "\n",
    "print(\"\\nFarthest\")\n",
    "print(\"GT Cmap:\", topK_query_cmap[-K:])\n",
    "print(\"Pred LV:\", topK_query_lv[-K:])\n",
    "\n",
    "print(set(topK_query_cmap[:K]) == set(topK_query_lv[:K]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Images\n",
    "\n",
    "def get_extreme_matches(trn_cmaps, topK_list, k=10):\n",
    "    top_K_close = []\n",
    "    bot_K_away = []\n",
    "\n",
    "    # 1 to K+1 since 0 index correspnds to the query itself\n",
    "    for i in range(1, k+1):\n",
    "        gripper, gnum = get_actual_idx(trn_cmaps, topK_list[i])    \n",
    "        img_f = os.path.join(images_dir, gripper, f\"img_graspnum_{gnum}.png\")\n",
    "        top_K_close.append(img_f)\n",
    "        \n",
    "        rev_idx = -i\n",
    "        f_gripper, f_gnum = get_actual_idx(trn_cmaps, topK_list[rev_idx])    \n",
    "        far_img_f = os.path.join(images_dir, f_gripper, f\"img_graspnum_{f_gnum}.png\")\n",
    "        bot_K_away.append(far_img_f)\n",
    "    \n",
    "    return top_K_close, bot_K_away\n",
    "    \n",
    "\n",
    "close_cmap, far_cmap = get_extreme_matches(sdf_dataset.cmaps, topK_query_cmap, k=10)\n",
    "\n",
    "close_lv, far_lv = get_extreme_matches(sdf_dataset.cmaps, topK_query_lv, k=10)\n",
    "\n",
    "\n",
    "# Populate the PIL images\n",
    "\n",
    "## For the cmap (ground truth)\n",
    "imgs_close_cmap = [Image.open(_img) for _img in close_cmap]\n",
    "imgs_far_cmap = [Image.open(_img) for _img in far_cmap]\n",
    "\n",
    "## For the latent vectors\n",
    "imgs_close_lv = [Image.open(_img) for _img in close_lv]\n",
    "imgs_far_lv = [Image.open(_img) for _img in far_lv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://keestalkstech.com/2020/05/plotting-a-grid-of-pil-images-in-jupyter/\n",
    "\n",
    "def display_images(\n",
    "    images: list,\n",
    "    overall_title='Sample title',\n",
    "    columns=6, width=20, height=8, max_images=15, \n",
    "    label_wrap_length=50, label_font_size=8):\n",
    "\n",
    "    if len(images) > max_images:\n",
    "        print(f\"Showing {max_images} images of {len(images)}:\")\n",
    "        images=images[0:max_images]\n",
    "\n",
    "    height = 1 + max(height, int(len(images)/columns) * height)\n",
    "    plt.figure(figsize=(width, height))\n",
    "    plt.title(overall_title)\n",
    "    for i, image in enumerate(images):\n",
    "\n",
    "        plt.subplot(int(len(images) / columns + 1), columns, i + 1)\n",
    "        plt.imshow(image)\n",
    "\n",
    "        if hasattr(image, 'filename'):\n",
    "            title=image.filename\n",
    "            if title.endswith(\"/\"): title = title[0:-1]\n",
    "            title=os.path.basename(title)\n",
    "            title=textwrap.wrap(title, label_wrap_length)\n",
    "            title=\"\\n\".join(title)\n",
    "            plt.title(title, fontsize=label_font_size)\n",
    "\n",
    "# Function to display the images in a grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_img_f = os.path.join(images_dir, query_gripper, f\"img_graspnum_{query_gnum}.png\")\n",
    "q_img = Image.open(query_img_f)\n",
    "print(\"QUERY IMAGE\")\n",
    "plt.imshow(q_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CLOSEST according to Contact Map (G.T)\")\n",
    "\n",
    "display_images(imgs_close_cmap, overall_title=\"Closest Cmap (GT)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CLOSEST according to Learned latent vector (Z) space\")\n",
    "\n",
    "display_images(imgs_close_lv, overall_title=\"Closest L.V\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"FARTHEST according to Contact Map (G.T)\")\n",
    "\n",
    "display_images(imgs_far_cmap, overall_title=\"FARTHEST Cmap (GT)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"FARTHEST according to Learned latent vector (Z) space\")\n",
    "\n",
    "display_images(imgs_far_lv, overall_title=\"FARTHEST L.V\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "828396f6010f0730e9cd4f02afef87f2dfb58bfe79cbcd1eff170bf9426e2a48"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
