{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "import open3d as o3d\n",
    "\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('..')\n",
    "import utils.misc as ws\n",
    "import utils.data_utils\n",
    "import utils.train_utils\n",
    "import utils.eval_utils\n",
    "import utils.mesh\n",
    "import utils.dataset as d\n",
    "import models.networks as arch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8194, 3)\n"
     ]
    }
   ],
   "source": [
    "# DATA_SOURCE = '/home/ninad/Desktop/Docs/phd-res/proj-irvl-grasp-transfer/code/docker-data/output_dataset/'\n",
    "# DATA_SOURCE = '/home/ninad/Desktop/multi-finger-grasping/output_dataset/'\n",
    "DATA_SOURCE = '/mnt/Data/eval_dataset-8ycb-5gripper-10grasps/'\n",
    "\n",
    "object_model_name = \"003_cracker_box_google_16k_textured_scale_1000\"\n",
    "\n",
    "EXPERIMENTS_DIR = '../experiments/all5_003_dsdf_50_varcmap'\n",
    "CHECKPOINT = 'latest'\n",
    "\n",
    "split_filename = os.path.join(EXPERIMENTS_DIR, 'split_validation.json')\n",
    "specs_filename = os.path.join(EXPERIMENTS_DIR, \"specs.json\")\n",
    "\n",
    "LATENT_CODE_DIR = ws.latent_codes_subdir\n",
    "reconstructions_subdir = ws.reconstructions_subdir\n",
    "reconstruction_codes_subdir = ws.reconstruction_codes_subdir\n",
    "\n",
    "# Load the object point cloud\n",
    "model_pc_file = os.path.join(DATA_SOURCE, object_model_name, 'object_point_cloud.ply')\n",
    "obj_pcd = o3d.io.read_point_cloud(model_pc_file)\n",
    "gt_obj_pc_points = np.asarray(obj_pcd.points)\n",
    "print(gt_obj_pc_points.shape)\n",
    "\n",
    "# Load the normalization params:\n",
    "norm_file = os.path.join(DATA_SOURCE, object_model_name, 'norm_params.npz')\n",
    "norm_npz = np.load(norm_file)\n",
    "offset = norm_npz['offset']\n",
    "scale = norm_npz['scale']\n",
    "\n",
    "# Normalize the object point cloud\n",
    "gt_obj_pc_points = (gt_obj_pc_points - offset) / scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "specs = json.load(open(specs_filename))\n",
    "latent_size = specs[\"CodeLength\"]\n",
    "gripper_weight = specs[\"GripperWeight\"]\n",
    "num_grippers = specs[\"NumGrippers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = arch.dsdfDecoder(\n",
    "    latent_size, \n",
    "    **specs[\"NetworkSpecs\"]\n",
    "    ).cuda()\n",
    "\n",
    "decoder = torch.nn.DataParallel(decoder)\n",
    "\n",
    "saved_model_state = torch.load(\n",
    "    os.path.join(\n",
    "        EXPERIMENTS_DIR, ws.model_params_subdir, CHECKPOINT + \".pth\")\n",
    ")\n",
    "\n",
    "saved_model_epoch = saved_model_state[\"epoch\"]\n",
    "\n",
    "decoder.load_state_dict(saved_model_state[\"model_state_dict\"])\n",
    "\n",
    "decoder = decoder.module.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(split_filename, \"r\") as f:\n",
    "    split = json.load(f)\n",
    "\n",
    "# npz_filenames = utils.data_utils.dsdf_get_instance_filenames(\n",
    "#     args.data_source, split)\n",
    "cmap_f, grp_names, gpc_f, npz_filenames = utils.data_utils.get_instance_filelist(DATA_SOURCE, split)\n",
    "\n",
    "# random.shuffle(npz_filenames) # WHY??? DISABLE THIS FOR CHECKING REPRODUCIBILITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reconstructed_code_filename(experiment_dir, epoch, ycb_model, gripper_name, instance_name):\n",
    "    return os.path.join(\n",
    "        experiment_dir,\n",
    "        reconstructions_subdir,\n",
    "        str(epoch),\n",
    "        reconstruction_codes_subdir,\n",
    "        f\"{ycb_model}-sdf-{gripper_name}-{instance_name}.pth\")\n",
    "    # ycb_model + '-sdf-' + gripper_name + '-' + instance_name + \".pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 /sdf/panda_grasp/sdf_graspnum_2.npz\n",
      "(224048, 3)\n"
     ]
    }
   ],
   "source": [
    "index_to_select = random.randint(0, len(npz_filenames)-1)\n",
    "\n",
    "npz = npz_filenames[index_to_select]\n",
    "gripper = grp_names[index_to_select]\n",
    "print(index_to_select, npz[-35:])\n",
    "npz_instance_name = os.path.split(npz)[-1].split('.')[0]\n",
    "lvec_file = get_reconstructed_code_filename(EXPERIMENTS_DIR, saved_model_epoch,\n",
    "                                            object_model_name, gripper, npz_instance_name)\n",
    "latent_vec = torch.load(lvec_file)\n",
    "latent_vec = latent_vec.squeeze()\n",
    "# latent_vec = latent_vecs[index_to_select].squeeze()\n",
    "# print(latent_vec.shape)\n",
    "\n",
    "\n",
    "# Load the point cloud corresponding to this grasp/gripper\n",
    "grp_pc_file = utils.eval_utils.extract_pcfile_from_npzfile(npz)\n",
    "grp_pcd = o3d.io.read_point_cloud(grp_pc_file)\n",
    "gt_grp_pc_points = np.asarray(grp_pcd.points)\n",
    "# Normalize the loaded points\n",
    "gt_grp_pc_points = (gt_grp_pc_points - offset) / scale\n",
    "\n",
    "print(gt_grp_pc_points.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     queries, sdf_obj, sdf_grp = utils.eval_utils.eval_query_pc(decoder, latent_vec.cuda(), queries)\n",
    "\n",
    "# Try with random queries instead:\n",
    "with torch.no_grad():\n",
    "    queries, sdf_obj, sdf_grp = utils.eval_utils.eval_random_query_pc(decoder, latent_vec.cuda(), num_samples=1000000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11519, 3])\n",
      "torch.Size([8549, 3])\n"
     ]
    }
   ],
   "source": [
    "EPS = 1e-4\n",
    "gen_grp_points = queries[sdf_grp < EPS]\n",
    "print(gen_grp_points.shape)\n",
    "\n",
    "gen_obj_points = queries[sdf_obj < EPS]\n",
    "print(gen_obj_points.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0011767164521415139, 0.00010762797866885798)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.eval_utils.compute_pc_chamfer(gt_obj_pc_points, gen_obj_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.009285194853763284, 0.00020036756071781643)\n"
     ]
    }
   ],
   "source": [
    "print(utils.eval_utils.compute_pc_chamfer(gt_grp_pc_points, gen_grp_points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrender\n",
    "# Just pass the points you want to visualize\n",
    "def plt_points_3d(pts):\n",
    "    colors = np.zeros(pts.shape)\n",
    "    cloud = pyrender.Mesh.from_points(pts, colors=colors)\n",
    "    scene = pyrender.Scene()\n",
    "    scene.add(cloud)\n",
    "    viewer = pyrender.Viewer(scene, use_raymond_lighting=True, point_size=2)\n",
    "\n",
    "# Pass the point as well as the sdf to see inside/outside points\n",
    "def plt_points_sdf(pts, sdf, eps=1e-4):\n",
    "    colors = np.zeros(pts.shape)\n",
    "    colors[sdf < eps, 1] = 1\n",
    "    colors[sdf > eps, 0] = 1\n",
    "    cloud = pyrender.Mesh.from_points(pts, colors=colors)\n",
    "    scene = pyrender.Scene()\n",
    "    scene.add(cloud)\n",
    "    viewer = pyrender.Viewer(scene, use_raymond_lighting=True, point_size=2)\n",
    "\n",
    "def plt_points_sdf_compare(pts, sdf_gt, sdf_pred):\n",
    "    colors = np.zeros(pts.shape)\n",
    "    colors[sdf_gt < 0, 1] = 1\n",
    "    colors[sdf_gt > 0, 0] = 1\n",
    "    cloud = pyrender.Mesh.from_points(pts, colors=colors)\n",
    "    scene = pyrender.Scene()\n",
    "    scene.add(cloud)\n",
    "    viewer = pyrender.Viewer(scene, use_raymond_lighting=True, point_size=2)\n",
    "    \n",
    "    colors2 = np.zeros(pts.shape)\n",
    "    colors2[sdf_pred < 0, 1] = 1\n",
    "    colors2[sdf_pred > 0, 0] = 1\n",
    "    cloud2 = pyrender.Mesh.from_points(pts, colors=colors2)\n",
    "    scene2 = pyrender.Scene()\n",
    "    scene2.add(cloud2)\n",
    "    viewer = pyrender.Viewer(scene2, use_raymond_lighting=True, point_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_points_3d(queries[sdf_grp < 1e-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_points_3d(queries[sdf_obj < 1e-4])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "828396f6010f0730e9cd4f02afef87f2dfb58bfe79cbcd1eff170bf9426e2a48"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('grasp-sdf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
