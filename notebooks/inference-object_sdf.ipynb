{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('..')\n",
    "import utils.misc as ws\n",
    "import utils.data_utils\n",
    "import utils.train_utils\n",
    "import utils.eval_utils\n",
    "import utils.mesh\n",
    "import utils.dataset as d\n",
    "import models.networks as arch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SOURCE = '/home/ninad/Desktop/Docs/phd-res/proj-irvl-grasp-transfer/code/docker-data/output_dataset/'\n",
    "# EXPERIMENTS_DIR = '../experiments/epochs_2000_weight_0.5/'\n",
    "EXPERIMENTS_DIR = '../experiments/all3_dsdf'\n",
    "CHECKPOINT = 'latest'\n",
    "LATENT_CODE_DIR = ws.latent_codes_subdir\n",
    "\n",
    "specs_filename = os.path.join(EXPERIMENTS_DIR, \"specs.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.419322772641168\n",
      "[-0.012431   -0.01178597  0.10826332]\n"
     ]
    }
   ],
   "source": [
    "object_model = '003_cracker_box_google_16k_textured_scale_1000'\n",
    "path_to_norm_npz = os.path.join(DATA_SOURCE, object_model, \"norm_params.npz\")\n",
    "data = np.load(path_to_norm_npz)\n",
    "\n",
    "obj_scale = data['scale']\n",
    "obj_offset = data['offset']\n",
    "\n",
    "print(obj_scale)\n",
    "print(obj_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "specs = json.load(open(specs_filename))\n",
    "latent_size = specs[\"CodeLength\"]\n",
    "gripper_weight = specs[\"GripperWeight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = arch.dsdfDecoder(latent_size, **specs[\"NetworkSpecs\"])\n",
    "\n",
    "decoder = torch.nn.DataParallel(decoder)\n",
    "\n",
    "saved_model_state = torch.load(\n",
    "    os.path.join(\n",
    "        EXPERIMENTS_DIR, ws.model_params_subdir, CHECKPOINT + \".pth\")\n",
    ")\n",
    "\n",
    "saved_model_epoch = saved_model_state[\"epoch\"]\n",
    "\n",
    "decoder.load_state_dict(saved_model_state[\"model_state_dict\"])\n",
    "\n",
    "decoder.eval()\n",
    "\n",
    "decoder = decoder.module.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([120, 256])\n"
     ]
    }
   ],
   "source": [
    "# Load the latent vectors learned during the training \n",
    "latent_vecs = ws.load_latent_vectors(EXPERIMENTS_DIR, CHECKPOINT)\n",
    "print(latent_vecs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "# For object point cloud sdf inference, any one latent vector is fine. \n",
    "# Later we can store the best scoring vector as a part of the model state.\n",
    "l_vec = latent_vecs[0]\n",
    "l_vec = l_vec.squeeze()\n",
    "print(l_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the query points here\n",
    "# Right now just doing a random sample\n",
    "queries = utils.eval_utils.sample_uniform_points_in_unit_sphere(amount=50000)\n",
    "\n",
    "# Perform the normalization here: Using the scale and offset\n",
    "queries = (queries - obj_offset) / obj_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "# The input queries are also a part of the output (ignore this)\n",
    "# The second var in the returned tuple is the object sdfs\n",
    "# The third var are gripper sdfs (ignore this)\n",
    "with torch.no_grad():\n",
    "    # queries, sdf_obj, sdf_grp = utils.eval_utils.eval_random_query_pc(decoder, l_vec.cuda(), )\n",
    "    queries, sdf_obj, _ = utils.eval_utils.eval_query_pc(decoder, l_vec, queries, max_batch_size=40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "828396f6010f0730e9cd4f02afef87f2dfb58bfe79cbcd1eff170bf9426e2a48"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('grasp-sdf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
