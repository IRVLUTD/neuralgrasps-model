{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17a6fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76d53b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('..')\n",
    "import utils.misc as ws\n",
    "import utils.data_utils\n",
    "import utils.train_utils\n",
    "import utils.eval_utils\n",
    "import utils.mesh\n",
    "import utils.dataset as d\n",
    "import models.networks as arch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931d7d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SOURCE = '/home/ninad/Desktop/Docs/phd-res/proj-irvl-grasp-transfer/code/docker-data/output_dataset/'\n",
    "# DATA_SOURCE = '/home/ninad/Desktop/multi-finger-grasping/output_dataset/'\n",
    "EXPERIMENTS_DIR = '../experiments/all3_gemb_varcmap_n200_run3_increased_batch_size_80/'\n",
    "CHECKPOINT = 'latest'\n",
    "split_filename = os.path.join(EXPERIMENTS_DIR, 'split_train.json')\n",
    "specs_filename = os.path.join(EXPERIMENTS_DIR, \"specs.json\")\n",
    "\n",
    "LATENT_CODE_DIR = ws.latent_codes_subdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bb0255",
   "metadata": {},
   "outputs": [],
   "source": [
    "specs = json.load(open(specs_filename))\n",
    "latent_size = specs[\"CodeLength\"]\n",
    "gripper_weight = specs[\"GripperWeight\"]\n",
    "num_grippers = specs[\"NumGrippers\"]\n",
    "grp_embedding_size = specs.get(\"GripperEmbeddingLength\", 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d632bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = arch.dsdfDecoder(\n",
    "    grp_embedding_size + latent_size, \n",
    "    **specs[\"NetworkSpecs\"]\n",
    "    ).cuda()\n",
    "\n",
    "decoder = torch.nn.DataParallel(decoder)\n",
    "\n",
    "saved_model_state = torch.load(\n",
    "    os.path.join(\n",
    "        EXPERIMENTS_DIR, ws.model_params_subdir, CHECKPOINT + \".pth\")\n",
    ")\n",
    "\n",
    "saved_model_epoch = saved_model_state[\"epoch\"]\n",
    "\n",
    "decoder.load_state_dict(saved_model_state[\"model_state_dict\"])\n",
    "\n",
    "decoder = decoder.module.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d26596",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(split_filename, \"r\") as f:\n",
    "    split = json.load(f)\n",
    "\n",
    "# npz_filenames = utils.data_utils.dsdf_get_instance_filenames(\n",
    "#     args.data_source, split)\n",
    "cmap_f, grp_names, gpc_f, npz_filenames = utils.data_utils.get_instance_filelist(DATA_SOURCE, split)\n",
    "\n",
    "# random.shuffle(npz_filenames) # WHY??? DISABLE THIS FOR CHECKING REPRODUCIBILITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1c7fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in npz_filenames[1:10]:\n",
    "    print(f[-35:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696dfe71",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_vecs = ws.load_latent_vectors(EXPERIMENTS_DIR, CHECKPOINT)\n",
    "gripper_vecs = ws.load_gripper_vectors(EXPERIMENTS_DIR, CHECKPOINT)\n",
    "print(latent_vecs.shape)\n",
    "print(gripper_vecs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de4e981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_to_select_1 = random.randint(0, len(npz_filenames)-1)\n",
    "# index_to_select_2 = random.randint(0, len(npz_filenames)-1)\n",
    "\n",
    "index_to_select_1 = 31\n",
    "index_to_select_2 = 500\n",
    "\n",
    "print(index_to_select_1, index_to_select_2)\n",
    "\n",
    "npz_1 = npz_filenames[index_to_select_1]\n",
    "npz_2 = npz_filenames[index_to_select_2]\n",
    "\n",
    "full_filename = npz_1\n",
    "\n",
    "print(index_to_select_1, npz_1[-35:])\n",
    "print(index_to_select_2, npz_2[-35:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79088c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gripper_idx = 2\n",
    "\n",
    "latent_vec_1 = latent_vecs[index_to_select_1].unsqueeze(1)\n",
    "latent_vec_2 = latent_vecs[index_to_select_2].unsqueeze(1)\n",
    "\n",
    "grp_vec_1 = gripper_vecs[2].unsqueeze(1)\n",
    "grp_vec_2 = gripper_vecs[1].unsqueeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbd9231",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_latent_code_1 = torch.cat([grp_vec_1, latent_vec_1], 0)\n",
    "combined_latent_code_2 = torch.cat([grp_vec_2, latent_vec_2], 0)\n",
    "print(combined_latent_code_1.shape)\n",
    "# print(combined_latent_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e14b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_latent_code_1 = combined_latent_code_1.squeeze()\n",
    "combined_latent_code_2 = combined_latent_code_2.squeeze()\n",
    "print(combined_latent_code_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53984650",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa46221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####### MESH RECONSTRUCTION CODE!\n",
    "\n",
    "# is_gripper = True\n",
    "\n",
    "# if is_gripper:\n",
    "#     mesh_filename = os.path.join(EXPERIMENTS_DIR, f'test_{npz[-15:]}')\n",
    "# else:\n",
    "#     mesh_filename = os.path.join(EXPERIMENTS_DIR, f'test_o_{npz[-15:]}')\n",
    "\n",
    "\n",
    "# latent_vec = latent_vec.squeeze().cuda()\n",
    "# with torch.no_grad():\n",
    "#     utils.mesh.create_mesh_custom(\n",
    "#         decoder, latent_vec, mesh_filename, N=256, max_batch=int(2 ** 18), isGripper=is_gripper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da73c68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7014bec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: HAVE SHUFFLE = FALSE SO THAT SAME DATA POINT IS LOADED AS index_to_select\n",
    "\n",
    "# sdf_dataset = d.SDFSamples(DATA_SOURCE, split, 1000000)\n",
    "\n",
    "sdf_dataset = d.MultiGripperSamples(DATA_SOURCE, split, 100000)\n",
    "\n",
    "sdf_loader = torch.utils.data.DataLoader(\n",
    "    sdf_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    "    drop_last=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae61d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_gidx_1, _, samples_1, idx_1, npzfile_1 = sdf_dataset[index_to_select_1]\n",
    "_gidx_1, _, samples_2, idx_2, npzfile_2 = sdf_dataset[index_to_select_2]\n",
    "print(npzfile_1[-40:], npzfile_2[-40:])\n",
    "\n",
    "# queries = samples[:, :3] # Need to pass this through the network\n",
    "# gt_sdf_obj = samples[:, 3].squeeze().numpy()\n",
    "# gt_sdf_grp = samples[:, 4].squeeze().numpy()\n",
    "# print(gt_sdf_grp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bafb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a1e48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cvx_combination(l1, l2, alpha):\n",
    "    return l1 * alpha + (1 - alpha) * l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368d5294",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_list = np.linspace(0, 1, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe39f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     queries, sdf_obj, sdf_grp = utils.eval_utils.eval_query_pc(decoder, latent_vec.cuda(), queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7fbfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = 4\n",
    "# cvx_code = get_cvx_combination(latent_vec_1, latent_vec_2, alpha_list[idx])\n",
    "# cvx_code = cvx_code.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564e2acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# queries, sdf_obj, sdf_grp = utils.eval_utils.eval_random_query_pc(decoder, cvx_code, num_samples=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8235514",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_codes = [get_cvx_combination(combined_latent_code_1, combined_latent_code_2, alpha_list[i]) for i in range(len(alpha_list))]\n",
    "\n",
    "results = [utils.eval_utils.eval_random_query_pc(decoder, latent_codes[i].cuda(), num_samples=100000) for i in range(len(alpha_list))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d47cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 7\n",
    "\n",
    "queries, sdf_obj, sdf_grp = results[idx]\n",
    "queries = queries.detach().cpu().numpy()\n",
    "sdf_obj = sdf_obj.detach().cpu().numpy()\n",
    "sdf_grp = sdf_grp.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15e535e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sdf_grp.shape)\n",
    "print(sdf_obj.shape)\n",
    "print(queries.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0989d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sdf(queries[sdf_obj < 1e-4], sdf_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99742906",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_sdf_2(xyz, sdf, xyz2, sdf2, title='Sample_Title', n_display=10000, fname=None):\n",
    "    fig = plt.figure(figsize = (10,10))\n",
    "    ax = fig.add_subplot(111, projection='3d')    \n",
    "\n",
    "    ind = np.random.choice(range(xyz.shape[0]), n_display)\n",
    "    data = xyz[ind].T\n",
    "    \n",
    "\n",
    "    ind2 = np.random.choice(range(xyz2.shape[0]), n_display)\n",
    "    data2 = xyz2[ind].T\n",
    "    \n",
    "    ax.scatter(data[0], data[2], data[1], s=5, c=sdf[ind])\n",
    "    ax.view_init(20, 100)\n",
    "    limit = (-0.95, 0.95)\n",
    "    ax.set_xlim3d(*limit)\n",
    "    ax.set_ylim3d(*limit)\n",
    "    ax.set_zlim3d(*limit)\n",
    "    plt.title(title)\n",
    "    if fname:\n",
    "        plt.savefig(fname)\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def plot_sdf(xyz, sdf, title='Sample_Title', n_display=10000, fname=None):\n",
    "    fig = plt.figure(figsize = (10,10))\n",
    "    ax = fig.add_subplot(111, projection='3d')    \n",
    "\n",
    "    ind = np.random.choice(range(xyz.shape[0]), n_display)\n",
    "    data = xyz[ind].T\n",
    "\n",
    "    ax.scatter(data[0], data[2], data[1], s=5, c=sdf[ind])\n",
    "    ax.view_init(20, 100)\n",
    "    limit = (-0.95, 0.95)\n",
    "    ax.set_xlim3d(*limit)\n",
    "    ax.set_ylim3d(*limit)\n",
    "    ax.set_zlim3d(*limit)\n",
    "    plt.title(title)\n",
    "    if fname:\n",
    "        plt.savefig(fname)\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def plot_sdf_with_box(xyz, sdf, box_pts, title='Sample_Title', n_display=10000, fname=None):\n",
    "    fig = plt.figure(figsize = (10,10))\n",
    "    ax = fig.add_subplot(111, projection='3d')    \n",
    "\n",
    "    ind = np.random.choice(range(xyz.shape[0]), n_display)\n",
    "    data = xyz[ind].T\n",
    "    \n",
    "    ax.scatter(data[0], data[2], data[1], s=5, c=sdf[ind])\n",
    "    ax.scatter(box_pts[0], box_pts[2], box_pts[1], s=2, c='red')\n",
    "    \n",
    "    ax.view_init(20, 100)\n",
    "    limit = (-0.95, 0.95)\n",
    "    ax.set_xlim3d(*limit)\n",
    "    ax.set_ylim3d(*limit)\n",
    "    ax.set_zlim3d(*limit)\n",
    "    plt.title(title)\n",
    "    if fname:\n",
    "        plt.savefig(fname)\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb9f7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_data = queries[sdf_obj < 1e-3]\n",
    "indices = np.random.choice(range(box_data.shape[0]), 1000)\n",
    "box_data = box_data[indices].T\n",
    "\n",
    "for i in range(len(alpha_list)):\n",
    "    queries, sdf_obj, sdf_grp = results[i]\n",
    "    queries = queries.detach().cpu().numpy()\n",
    "    sdf_obj = sdf_obj.detach().cpu().numpy()\n",
    "    sdf_grp = sdf_grp.detach().cpu().numpy()    \n",
    "    EPS = -1e-4\n",
    "    ind_grp = sdf_grp <= EPS\n",
    "    \n",
    "    fname_save = os.path.join(EXPERIMENTS_DIR, 'viz', \n",
    "                              f'interpolation_{index_to_select_1}_{index_to_select_2}_{alpha_list[i]:.1f}.png')\n",
    "    \n",
    "    plot_sdf_with_box(queries[ind_grp], sdf_obj[ind_grp], box_data, \n",
    "             title=f'Grasps={index_to_select_1, index_to_select_2} ; Coef={alpha_list[i]:.1f}',\n",
    "             fname=fname_save)\n",
    "\n",
    "    \n",
    "    \n",
    "# EPS = -1e-4\n",
    "# ind_grp = sdf_grp <= EPS\n",
    "# plot_sdf(queries[ind_grp], sdf_obj[ind_grp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be09e674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120e2d60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc03720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrender\n",
    "# Just pass the points you want to visualize\n",
    "def plt_points_3d(pts):\n",
    "    colors = np.zeros(pts.shape)\n",
    "    cloud = pyrender.Mesh.from_points(pts, colors=colors)\n",
    "    scene = pyrender.Scene()\n",
    "    scene.add(cloud)\n",
    "    viewer = pyrender.Viewer(scene, use_raymond_lighting=True, point_size=2)\n",
    "\n",
    "# Pass the point as well as the sdf to see inside/outside points\n",
    "def plt_points_sdf(pts, sdf, eps=1e-4):\n",
    "    colors = np.zeros(pts.shape)\n",
    "    colors[sdf < eps, 1] = 1\n",
    "    colors[sdf > eps, 0] = 1\n",
    "    cloud = pyrender.Mesh.from_points(pts, colors=colors)\n",
    "    scene = pyrender.Scene()\n",
    "    scene.add(cloud)\n",
    "    viewer = pyrender.Viewer(scene, use_raymond_lighting=True, point_size=2)\n",
    "\n",
    "def plt_points_sdf_compare(pts, sdf_gt, sdf_pred):\n",
    "    colors = np.zeros(pts.shape)\n",
    "    colors[sdf_gt < 0, 1] = 1\n",
    "    colors[sdf_gt > 0, 0] = 1\n",
    "    cloud = pyrender.Mesh.from_points(pts, colors=colors)\n",
    "    scene = pyrender.Scene()\n",
    "    scene.add(cloud)\n",
    "    viewer = pyrender.Viewer(scene, use_raymond_lighting=True, point_size=2)\n",
    "    \n",
    "    colors2 = np.zeros(pts.shape)\n",
    "    colors2[sdf_pred < 0, 1] = 1\n",
    "    colors2[sdf_pred > 0, 0] = 1\n",
    "    cloud2 = pyrender.Mesh.from_points(pts, colors=colors2)\n",
    "    scene2 = pyrender.Scene()\n",
    "    scene2.add(cloud2)\n",
    "    viewer = pyrender.Viewer(scene2, use_raymond_lighting=True, point_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bbe640",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_points_3d(queries[sdf_grp < 1e-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486169cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_points_3d(queries[sdf_obj < 1e-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03dc38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_points_sdf(queries, sdf_grp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca3d3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_points_sdf(queries, sdf_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33b3943",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "828396f6010f0730e9cd4f02afef87f2dfb58bfe79cbcd1eff170bf9426e2a48"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('grasp-sdf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
