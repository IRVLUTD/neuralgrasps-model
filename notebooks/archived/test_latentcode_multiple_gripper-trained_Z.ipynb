{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b17a6fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b76d53b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('..')\n",
    "import utils.misc as ws\n",
    "import utils.data_utils\n",
    "import utils.train_utils\n",
    "import utils.eval_utils\n",
    "import utils.mesh\n",
    "import utils.dataset as d\n",
    "import models.networks as arch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "931d7d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SOURCE = '/home/ninad/Desktop/Docs/phd-res/proj-irvl-grasp-transfer/code/docker-data/output_dataset/'\n",
    "# EXPERIMENTS_DIR = '../experiments/epochs_2000_weight_0.5/'\n",
    "EXPERIMENTS_DIR = '../experiments/all3_toy_grp-pc-encoder/'\n",
    "CHECKPOINT = 'latest'\n",
    "split_filename = os.path.join(EXPERIMENTS_DIR, 'split_train.json')\n",
    "                              \n",
    "specs_filename = os.path.join(EXPERIMENTS_DIR, \"specs.json\")\n",
    "\n",
    "LATENT_CODE_DIR = ws.latent_codes_subdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3bb0255",
   "metadata": {},
   "outputs": [],
   "source": [
    "specs = json.load(open(specs_filename))\n",
    "\n",
    "latent_size = specs[\"CodeLength\"]\n",
    "gripper_weight = specs[\"GripperWeight\"]\n",
    "num_samp_per_scene = specs[\"SamplesPerScene\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0d632bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_grp = arch.ResnetPointnet(c_dim=latent_size, dim=3, hidden_dim=256)\n",
    "\n",
    "decoder = arch.dsdfDecoder(2*latent_size, **specs[\"NetworkSpecs\"])\n",
    "\n",
    "encoderDecoder = arch.MultiGripperDecoder(encoder_grp, decoder, num_samp_per_scene)\n",
    "\n",
    "encoderDecoder = torch.nn.DataParallel(encoderDecoder)\n",
    "\n",
    "saved_model_state = torch.load(\n",
    "    os.path.join(\n",
    "        EXPERIMENTS_DIR, ws.model_params_subdir, CHECKPOINT + \".pth\")\n",
    ")\n",
    "\n",
    "saved_model_epoch = saved_model_state[\"epoch\"]\n",
    "\n",
    "encoderDecoder.load_state_dict(saved_model_state[\"model_state_dict\"])\n",
    "\n",
    "encoderDecoder = encoderDecoder.module.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5d26596",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Non-existent file count: 0\n"
     ]
    }
   ],
   "source": [
    "with open(split_filename, \"r\") as f:\n",
    "    split = json.load(f)\n",
    "\n",
    "# npz_filenames = utils.data_utils.dsdf_get_instance_filenames(\n",
    "#     args.data_source, split)\n",
    "gpc_files, npz_filenames = utils.data_utils.get_instance_filelist(DATA_SOURCE, split)\n",
    "\n",
    "# random.shuffle(npz_filenames) # WHY??? DISABLE THIS FOR CHECKING REPRODUCIBILITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c1c7fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df/fetch_gripper/sdf_graspnum_0.npz\n",
      "000/sdf/Barrett/sdf_graspnum_10.npz\n",
      "0/sdf/HumanHand/sdf_graspnum_20.npz\n"
     ]
    }
   ],
   "source": [
    "for f in npz_filenames:\n",
    "    print(f[-35:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a578f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ud/fetch_gripper.npz\n",
      "nt_cloud/Barrett.npz\n",
      "_cloud/HumanHand.npz\n"
     ]
    }
   ],
   "source": [
    "for gpc in gpc_files:\n",
    "    print(gpc[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "696dfe71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 256])\n"
     ]
    }
   ],
   "source": [
    "latent_vecs = ws.load_latent_vectors(EXPERIMENTS_DIR, CHECKPOINT)\n",
    "print(latent_vecs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3de4e981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 000/sdf/Barrett/sdf_graspnum_10.npz\n"
     ]
    }
   ],
   "source": [
    "index_to_select = random.randint(0, len(npz_filenames)-1)\n",
    "\n",
    "npz = npz_filenames[index_to_select]\n",
    "gpc = gpc_files[index_to_select]\n",
    "\n",
    "full_filename = npz\n",
    "\n",
    "print(index_to_select, npz[-35:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b79088c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_vec = latent_vecs[index_to_select]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1e14b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "latent_vec = latent_vec.squeeze()\n",
    "print(latent_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53984650",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a22f7406",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Non-existent file count: 0\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: HAVE SHUFFLE = FALSE SO THAT SAME DATA POINT IS LOADED AS index_to_select\n",
    "\n",
    "sdf_dataset = d.MultiGripperSamples(DATA_SOURCE, split, 1000000)\n",
    "\n",
    "sdf_loader = torch.utils.data.DataLoader(\n",
    "    sdf_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    "    drop_last=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "987d8709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ale_1000/sdf/Barrett/sdf_graspnum_10.npz\n"
     ]
    }
   ],
   "source": [
    "# samples, npzfile = next(iter(sdf_loader))\n",
    "gripper_pc, samples, idx, npzfile = sdf_dataset[index_to_select]\n",
    "print(npzfile[-40:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11f25fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2aa46221",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-2, 1], but got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m latent_vec \u001b[38;5;241m=\u001b[39m latent_vec\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 13\u001b[0m     \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmesh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_mesh_custom\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoderDecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_vec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmesh_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgripper_pc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgripper_pts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m18\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43misGripper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_gripper\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Docs/phd-res/proj-irvl-grasp-transfer/code/grasp-encoding/notebooks/../utils/mesh.py:56\u001b[0m, in \u001b[0;36mcreate_mesh_custom\u001b[0;34m(decoder, latent_vec, filename, gripper_pc, N, max_batch, offset, scale, isGripper)\u001b[0m\n\u001b[1;32m     53\u001b[0m sample_subset \u001b[38;5;241m=\u001b[39m samples[head: \u001b[38;5;28mmin\u001b[39m(\n\u001b[1;32m     54\u001b[0m     head \u001b[38;5;241m+\u001b[39m max_batch, num_samples), \u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gripper_pc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 56\u001b[0m     tmp \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_sdf_encoderDecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_vec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_subset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgripper_pc\u001b[49m\u001b[43m)\u001b[49m[SDF_IDX]\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     tmp \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mtrain_utils\u001b[38;5;241m.\u001b[39mdsdf_decode_sdf(\n\u001b[1;32m     60\u001b[0m         decoder, latent_vec, sample_subset)[SDF_IDX]\n",
      "File \u001b[0;32m~/Desktop/Docs/phd-res/proj-irvl-grasp-transfer/code/grasp-encoding/notebooks/../utils/train_utils.py:19\u001b[0m, in \u001b[0;36mdecode_sdf_encoderDecoder\u001b[0;34m(encoderDecoder, latent_vector, queries, gripper_pc)\u001b[0m\n\u001b[1;32m     16\u001b[0m     latent_repeat \u001b[38;5;241m=\u001b[39m latent_vector\u001b[38;5;241m.\u001b[39mexpand(num_samples, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     17\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([latent_repeat, queries], \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m sdf_obj, sdf_grp \u001b[38;5;241m=\u001b[39m \u001b[43mencoderDecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgripper_pc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sdf_obj, sdf_grp\n",
      "File \u001b[0;32m~/anaconda3/envs/grasp-sdf/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/Docs/phd-res/proj-irvl-grasp-transfer/code/grasp-encoding/notebooks/../models/networks.py:138\u001b[0m, in \u001b[0;36mMultiGripperDecoder.forward\u001b[0;34m(self, pc_input, queries)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, pc_input, queries):\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;66;03m# queries should be whatever was passed to the the org dSDF auto-decoder\u001b[39;00m\n\u001b[0;32m--> 138\u001b[0m     pc_latent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpc_input\u001b[49m\u001b[43m)\u001b[49m        \n\u001b[1;32m    139\u001b[0m     pc_encoding \u001b[38;5;241m=\u001b[39m pc_latent\u001b[38;5;241m.\u001b[39mrepeat_interleave(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samp_per_scene, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    140\u001b[0m     decoder_inputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([pc_encoding, queries], \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/grasp-sdf/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/Docs/phd-res/proj-irvl-grasp-transfer/code/grasp-encoding/notebooks/../models/networks.py:259\u001b[0m, in \u001b[0;36mResnetPointnet.forward\u001b[0;34m(self, p, cond)\u001b[0m\n\u001b[1;32m    257\u001b[0m net \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock_0(net)\n\u001b[1;32m    258\u001b[0m pooled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(net, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mexpand(net\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m--> 259\u001b[0m net \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpooled\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    261\u001b[0m net \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock_1(net)\n\u001b[1;32m    262\u001b[0m pooled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(net, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mexpand(net\u001b[38;5;241m.\u001b[39msize())\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 2)"
     ]
    }
   ],
   "source": [
    "####### MESH RECONSTRUCTION CODE!\n",
    "\n",
    "is_gripper = True\n",
    "\n",
    "if is_gripper:\n",
    "    mesh_filename = os.path.join(EXPERIMENTS_DIR, f'test_{npz[-15:]}')\n",
    "else:\n",
    "    mesh_filename = os.path.join(EXPERIMENTS_DIR, f'test_o_{npz[-15:]}')\n",
    "\n",
    "\n",
    "latent_vec = latent_vec.squeeze().cuda()\n",
    "with torch.no_grad():\n",
    "    utils.mesh.create_mesh_custom(\n",
    "        encoderDecoder, latent_vec.cuda(), mesh_filename, gripper_pc=gripper_pc.cuda(), N=256, max_batch=int(2 ** 18), isGripper=is_gripper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da73c68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7014bec7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ae61d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000,)\n"
     ]
    }
   ],
   "source": [
    "queries = samples[:, :3] # Need to pass this through the network\n",
    "gt_sdf_obj = samples[:, 3].squeeze().numpy()\n",
    "gt_sdf_grp = samples[:, 4].squeeze().numpy()\n",
    "print(gt_sdf_grp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81bafb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000000, 5])\n"
     ]
    }
   ],
   "source": [
    "print(samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9f1963e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 3])\n"
     ]
    }
   ],
   "source": [
    "print(gripper_pc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02997ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 3])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gripper_pc.unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a1e48a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1fe39f5b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 16384 but got size 576 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 2\u001b[0m     queries, sdf_obj, sdf_grp \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_query_pc_multi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoderDecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_vec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgripper_pc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16384\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Docs/phd-res/proj-irvl-grasp-transfer/code/grasp-encoding/notebooks/../utils/eval_utils.py:104\u001b[0m, in \u001b[0;36meval_query_pc_multi\u001b[0;34m(encoderDecoder, latent_vec, queries, gripper_pc, max_batch_size)\u001b[0m\n\u001b[1;32m    102\u001b[0m end_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(head \u001b[38;5;241m+\u001b[39m max_batch_size, num_samples)\n\u001b[1;32m    103\u001b[0m sample_subset \u001b[38;5;241m=\u001b[39m xyz_samples[start_idx: end_idx, :\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m--> 104\u001b[0m sdf_obj, sdf_grp \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_sdf_encoderDecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoderDecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_vec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_subset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgripper_pc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m pred_sdf_obj[start_idx: end_idx] \u001b[38;5;241m=\u001b[39m sdf_obj\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m    107\u001b[0m pred_sdf_grp[start_idx: end_idx] \u001b[38;5;241m=\u001b[39m sdf_grp\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\n",
      "File \u001b[0;32m~/Desktop/Docs/phd-res/proj-irvl-grasp-transfer/code/grasp-encoding/notebooks/../utils/train_utils.py:19\u001b[0m, in \u001b[0;36mdecode_sdf_encoderDecoder\u001b[0;34m(encoderDecoder, latent_vector, queries, gripper_pc)\u001b[0m\n\u001b[1;32m     16\u001b[0m     latent_repeat \u001b[38;5;241m=\u001b[39m latent_vector\u001b[38;5;241m.\u001b[39mexpand(num_samples, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     17\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([latent_repeat, queries], \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m sdf_obj, sdf_grp \u001b[38;5;241m=\u001b[39m \u001b[43mencoderDecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgripper_pc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sdf_obj, sdf_grp\n",
      "File \u001b[0;32m~/anaconda3/envs/grasp-sdf/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/Docs/phd-res/proj-irvl-grasp-transfer/code/grasp-encoding/notebooks/../models/networks.py:140\u001b[0m, in \u001b[0;36mMultiGripperDecoder.forward\u001b[0;34m(self, pc_input, queries)\u001b[0m\n\u001b[1;32m    138\u001b[0m pc_latent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(pc_input)        \n\u001b[1;32m    139\u001b[0m pc_encoding \u001b[38;5;241m=\u001b[39m pc_latent\u001b[38;5;241m.\u001b[39mrepeat_interleave(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samp_per_scene, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 140\u001b[0m decoder_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpc_encoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueries\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m sdf_obj, sdf_gripper \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(decoder_inputs)\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sdf_obj, sdf_gripper\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 16384 but got size 576 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    queries, sdf_obj, sdf_grp = utils.eval_utils.eval_query_pc_multi(encoderDecoder, latent_vec.cuda(), queries.cuda(), gripper_pc.unsqueeze(0).cuda(), max_batch_size=16384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7fbfbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564e2acd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8235514",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d47cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = queries.detach().cpu().numpy()\n",
    "sdf_obj = sdf_obj.detach().cpu().numpy()\n",
    "sdf_grp = sdf_grp.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15e535e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sdf_grp.shape)\n",
    "print(sdf_obj.shape)\n",
    "print(queries.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99742906",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_sdf(xyz, sdf, title='Sample_Title', n_display=10000):\n",
    "    fig = plt.figure(figsize = (10,10))\n",
    "    ax = fig.add_subplot(111, projection='3d')    \n",
    "\n",
    "    ind = np.random.choice(range(xyz.shape[0]), n_display)\n",
    "    data = xyz[ind].T\n",
    "\n",
    "    ax.scatter(data[0], data[2], data[1], s=5, c=sdf[ind])\n",
    "    ax.view_init(20, 100)\n",
    "    limit = (-0.95, 0.95)\n",
    "    ax.set_xlim3d(*limit)\n",
    "    ax.set_ylim3d(*limit)\n",
    "    ax.set_zlim3d(*limit)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb9f7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = -1e-4\n",
    "# ind_obj =  np.where((y >= -EPS) & (y <= EPS))\n",
    "ind_grp = sdf_grp <= EPS\n",
    "\n",
    "plot_sdf(queries[ind_grp], sdf_obj[ind_grp])\n",
    "\n",
    "min(sdf_grp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be09e674",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = -1e-4\n",
    "# ind_obj =  np.where((y >= -EPS) & (y <= EPS))\n",
    "ind_grp = gt_sdf_grp <= EPS\n",
    "\n",
    "plot_sdf(queries[ind_grp], gt_sdf_grp[ind_grp])\n",
    "\n",
    "min(gt_sdf_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120e2d60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc03720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrender\n",
    "# Just pass the points you want to visualize\n",
    "def plt_points_3d(pts):\n",
    "    colors = np.zeros(pts.shape)\n",
    "    cloud = pyrender.Mesh.from_points(pts, colors=colors)\n",
    "    scene = pyrender.Scene()\n",
    "    scene.add(cloud)\n",
    "    viewer = pyrender.Viewer(scene, use_raymond_lighting=True, point_size=2)\n",
    "\n",
    "# Pass the point as well as the sdf to see inside/outside points\n",
    "def plt_points_sdf(pts, sdf, eps=1e-4):\n",
    "    colors = np.zeros(pts.shape)\n",
    "    colors[sdf < eps, 1] = 1\n",
    "    colors[sdf > eps, 0] = 1\n",
    "    cloud = pyrender.Mesh.from_points(pts, colors=colors)\n",
    "    scene = pyrender.Scene()\n",
    "    scene.add(cloud)\n",
    "    viewer = pyrender.Viewer(scene, use_raymond_lighting=True, point_size=2)\n",
    "\n",
    "def plt_points_sdf_compare(pts, sdf_gt, sdf_pred):\n",
    "    colors = np.zeros(pts.shape)\n",
    "    colors[sdf_gt < 0, 1] = 1\n",
    "    colors[sdf_gt > 0, 0] = 1\n",
    "    cloud = pyrender.Mesh.from_points(pts, colors=colors)\n",
    "    scene = pyrender.Scene()\n",
    "    scene.add(cloud)\n",
    "    viewer = pyrender.Viewer(scene, use_raymond_lighting=True, point_size=2)\n",
    "    \n",
    "    colors2 = np.zeros(pts.shape)\n",
    "    colors2[sdf_pred < 0, 1] = 1\n",
    "    colors2[sdf_pred > 0, 0] = 1\n",
    "    cloud2 = pyrender.Mesh.from_points(pts, colors=colors2)\n",
    "    scene2 = pyrender.Scene()\n",
    "    scene2.add(cloud2)\n",
    "    viewer = pyrender.Viewer(scene2, use_raymond_lighting=True, point_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bbe640",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_points_3d(queries[sdf_grp < 1e-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486169cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_points_3d(queries[sdf_obj < 1e-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03dc38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_points_sdf(queries, sdf_grp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca3d3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_points_sdf(queries, sdf_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33b3943",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
